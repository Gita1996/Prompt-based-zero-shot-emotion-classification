{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27caed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.34      0.35      0.34      1555\n",
      "     disgust       0.14      0.50      0.22       761\n",
      "        fear       0.49      0.32      0.39      2816\n",
      "         joy       0.65      0.41      0.50      8240\n",
      "     sadness       0.39      0.49      0.44      3830\n",
      "    surprise       0.34      0.43      0.38      3849\n",
      "\n",
      "    accuracy                           0.42     21051\n",
      "   macro avg       0.39      0.42      0.38     21051\n",
      "weighted avg       0.49      0.42      0.43     21051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('TEC_nli_prompt-emotion-prediction_roberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emotion'].tolist()\n",
    "entailment_probabilities=data['prob_emotion'].tolist()\n",
    "max_entailment=list()\n",
    "\n",
    "for m in entailment_probabilities:\n",
    "    m = m.strip(\"[]\")\n",
    "\n",
    "# Step 2: Split the string by commas\n",
    "    string_elements = m.split(\",\")\n",
    "\n",
    "# Step 3: Convert each element to a float\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    \n",
    "#    r=list(m)\n",
    "#    print(m)\n",
    "#    for d in float_list:\n",
    " #       arr = [float(i) for i in d[1:-1].split(\",\")]\n",
    " #       max_index=np.argmax(arr)\n",
    "    max_entailment.append(max(float_list))\n",
    "\n",
    "data['prob_max']= max_entailment       \n",
    "\n",
    "data.to_csv('TEC_nli_prompt-emotion-prediction_roberta2.csv', index=False)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a6c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4684\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR-nli-prompt-expr-emo3-roberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emotion'].tolist()\n",
    "\n",
    "count=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]==y_pred[i]:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331224ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.48      0.51      1079\n",
      "     disgust       0.79      0.46      0.58      1066\n",
      "        fear       0.67      0.82      0.74      1076\n",
      "       guilt       0.45      0.68      0.54      1049\n",
      "         joy       0.93      0.89      0.91      1092\n",
      "     sadness       0.55      0.83      0.66      1082\n",
      "       shame       0.70      0.22      0.34      1071\n",
      "\n",
      "    accuracy                           0.63      7515\n",
      "   macro avg       0.66      0.63      0.61      7515\n",
      "weighted avg       0.66      0.63      0.61      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "#ISEAR-nli-prompt-expr-emo3-roberta.csv\n",
    "#ISEAR-nli-prompt-expr_emo3-Deberta.csv\n",
    "data = pd.read_csv('ISEAR-nli-prompt-expr_emo3-Deberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['expr_emo'].tolist()\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ef8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was disgusted at the behavior of these boys I work with in the scouting program. They showed a lack of interest, unrest, and at times just plain rude behavior. \n",
      "1066\n",
      "495\n",
      "0.9993113\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR-nli-prompt-expr_emo3-Deberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['expr_emo'].tolist()\n",
    "txt=data['text'].tolist()\n",
    "prob_max = data['prob_max'].tolist()\n",
    "\n",
    "\n",
    "count1=0\n",
    "count=0\n",
    "max_prob=0\n",
    "max_index=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='disgust':\n",
    "        count1+=1       \n",
    "    if y_true[i]==y_pred[i]=='disgust':\n",
    "        count+=1\n",
    "        if prob_max[i]>max_prob:\n",
    "            max_prob=prob_max[i]\n",
    "            max_index=i\n",
    "print(txt[max_index])            \n",
    "#and prob_max[i]>0.9\n",
    "print(count1)\n",
    "print(count)\n",
    "print(max_prob)\n",
    "# index 5680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73ee2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f24a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('ISEAR-nli-prompt-expr_emo3-Deberta.csv')\n",
    "d=data['labels'].tolist()\n",
    "r=sorted(list(set(d)))\n",
    "print(r)\n",
    "#['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62109c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was disgusted at the behavior of these boys I work with in the scouting program. They showed a lack of interest, unrest, and at times just plain rude behavior. \n",
      "1066\n",
      "432\n",
      "0.9993113\n",
      "5678\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR-nli-prompt-expr_emo3-Deberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['expr_emo'].tolist()\n",
    "txt=data['text'].tolist()\n",
    "prob_max = data['prob_max'].tolist()\n",
    "\n",
    "\n",
    "count1=0\n",
    "count=0\n",
    "max_prob=0\n",
    "max_index=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='disgust':\n",
    "        count1+=1       \n",
    "    if y_true[i]==y_pred[i]=='disgust' and prob_max[i]>0.9:\n",
    "        count+=1\n",
    "        if prob_max[i]>max_prob:\n",
    "            max_prob=prob_max[i]\n",
    "            max_index=i\n",
    "print(txt[max_index])            \n",
    "#and prob_max[i]>0.9\n",
    "print(count1)\n",
    "print(count)\n",
    "print(max_prob)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5910c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "495\n",
      "111\n",
      "116\n",
      "17\n",
      "144\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR-nli-prompt-expr_emo3-Deberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['expr_emo'].tolist()\n",
    "\n",
    "anger_count=0\n",
    "disgust_count=0\n",
    "fear_count=0\n",
    "guilt_count=0\n",
    "joy_count=0\n",
    "sadness_count=0\n",
    "shame_count=0\n",
    "\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='disgust':\n",
    "        if y_pred[i]=='anger':\n",
    "            anger_count+=1\n",
    "        if y_pred[i]=='disgust':\n",
    "            disgust_count+=1\n",
    "        if y_pred[i]=='fear':\n",
    "            fear_count+=1\n",
    "        if y_pred[i]=='guilt':\n",
    "            guilt_count+=1\n",
    "        if y_pred[i]=='joy':\n",
    "            joy_count+=1\n",
    "        if y_pred[i]=='sadness':\n",
    "            sadness_count+=1\n",
    "        if y_pred[i]=='shame':\n",
    "            shame_count+=1\n",
    "\n",
    "print(anger_count)\n",
    "print(disgust_count)\n",
    "print(fear_count)\n",
    "print(guilt_count)\n",
    "print(joy_count)\n",
    "print(sadness_count)\n",
    "print(shame_count)\n",
    "\n",
    "#disgust mistaken mostly with sadness count:144\n",
    "#shame mistaken mostly with guilt count:460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aeefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
