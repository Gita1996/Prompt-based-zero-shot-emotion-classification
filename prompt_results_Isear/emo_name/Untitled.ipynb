{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27caed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.34      0.35      0.34      1555\n",
      "     disgust       0.14      0.50      0.22       761\n",
      "        fear       0.49      0.32      0.39      2816\n",
      "         joy       0.65      0.41      0.50      8240\n",
      "     sadness       0.39      0.49      0.44      3830\n",
      "    surprise       0.34      0.43      0.38      3849\n",
      "\n",
      "    accuracy                           0.42     21051\n",
      "   macro avg       0.39      0.42      0.38     21051\n",
      "weighted avg       0.49      0.42      0.43     21051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('TEC_nli_prompt-emotion-prediction_roberta.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emotion'].tolist()\n",
    "entailment_probabilities=data['prob_emotion'].tolist()\n",
    "max_entailment=list()\n",
    "\n",
    "for m in entailment_probabilities:\n",
    "    m = m.strip(\"[]\")\n",
    "\n",
    "# Step 2: Split the string by commas\n",
    "    string_elements = m.split(\",\")\n",
    "\n",
    "# Step 3: Convert each element to a float\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    \n",
    "#    r=list(m)\n",
    "#    print(m)\n",
    "#    for d in float_list:\n",
    " #       arr = [float(i) for i in d[1:-1].split(\",\")]\n",
    " #       max_index=np.argmax(arr)\n",
    "    max_entailment.append(max(float_list))\n",
    "\n",
    "data['prob_max']= max_entailment       \n",
    "\n",
    "data.to_csv('TEC_nli_prompt-emotion-prediction_roberta2.csv', index=False)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46a6c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066\n",
      "339\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR_nli_Deberta_prompt2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "\n",
    "count1=0\n",
    "count=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='disgust':\n",
    "        count1+=1       \n",
    "    if y_true[i]==y_pred[i]=='disgust':\n",
    "        count+=1\n",
    "print(count1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021eb7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR_nli_Deberta_prompt2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "prob_max = data['prob_max'].tolist()\n",
    "\n",
    "count1=0\n",
    "count=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='anger':\n",
    "        count1+=1       \n",
    "    if y_true[i]==y_pred[i]=='anger' and prob_max[i]>0.9:\n",
    "        count+=1\n",
    "print(count1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('ISEAR_dataset2.csv')\n",
    "d=data['labels'].tolist()\n",
    "r=sorted(list(set(d)))\n",
    "print(r)\n",
    "#['anger', 'disgust', 'fear', 'guilt', 'joy', 'sadness', 'shame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331224ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.43      0.44      0.43      1079\n",
      "     disgust       0.70      0.41      0.52      1066\n",
      "        fear       0.78      0.49      0.60      1076\n",
      "       guilt       0.29      0.61      0.39      1049\n",
      "         joy       0.92      0.60      0.72      1092\n",
      "     sadness       0.49      0.79      0.60      1082\n",
      "       shame       0.58      0.22      0.32      1071\n",
      "\n",
      "    accuracy                           0.51      7515\n",
      "   macro avg       0.60      0.51      0.51      7515\n",
      "weighted avg       0.60      0.51      0.51      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR_dataset2_roberta_nli2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ef8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076\n",
      "835\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "#data = pd.read_csv('ISEAR_nli_Bart2.csv')\n",
    "data = pd.read_csv('ISEAR_nli_Deberta_prompt2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "txt=data['text'].tolist()\n",
    "prob_max = data['prob_max'].tolist()\n",
    "\n",
    "\n",
    "count1=0\n",
    "count=0\n",
    "max_prob=0\n",
    "max_index=0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='fear':\n",
    "        count1+=1       \n",
    "    if y_true[i]==y_pred[i]=='fear':\n",
    "        count+=1\n",
    "#        if prob_max[i]>max_prob:\n",
    "#            max_prob=prob_max[i]\n",
    "#            max_index=i\n",
    "#print(txt[max_index])            \n",
    "#and prob_max[i]>0.9\n",
    "print(count1)\n",
    "print(count)\n",
    "#print(max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d92ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "15\n",
      "181\n",
      "411\n",
      "20\n",
      "221\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#data = pd.read_csv('ISEAR-nli-prompt-emotion3-deberta.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "data = pd.read_csv('ISEAR_nli_Deberta_prompt2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "\n",
    "anger_count=0\n",
    "disgust_count=0\n",
    "fear_count=0\n",
    "guilt_count=0\n",
    "joy_count=0\n",
    "sadness_count=0\n",
    "shame_count=0\n",
    "\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='shame':\n",
    "        if y_pred[i]=='anger':\n",
    "            anger_count+=1\n",
    "        if y_pred[i]=='disgust':\n",
    "            disgust_count+=1\n",
    "        if y_pred[i]=='fear':\n",
    "            fear_count+=1\n",
    "        if y_pred[i]=='guilt':\n",
    "            guilt_count+=1\n",
    "        if y_pred[i]=='joy':\n",
    "            joy_count+=1\n",
    "        if y_pred[i]=='sadness':\n",
    "            sadness_count+=1\n",
    "        if y_pred[i]=='shame':\n",
    "            shame_count+=1\n",
    "\n",
    "print(anger_count)\n",
    "print(disgust_count)\n",
    "print(fear_count)\n",
    "print(guilt_count)\n",
    "print(joy_count)\n",
    "print(sadness_count)\n",
    "print(shame_count)\n",
    "\n",
    "#disgust mistaken mostly with sadness count:281\n",
    "#shame mistaken mostly with guilt count:411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "166909e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "5\n",
      "65\n",
      "33\n",
      "11\n",
      "923\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv('ISEAR_nli_Deberta_prompt2.csv')\n",
    "#ISEAR-nli-prompt-emotion-roberta.csv\n",
    "#data = pd.read_csv('ISEAR_nli_Bart2.csv')\n",
    "y_true = data['labels'].tolist()\n",
    "y_pred = data['emo_name'].tolist()\n",
    "\n",
    "anger_count=0\n",
    "disgust_count=0\n",
    "fear_count=0\n",
    "guilt_count=0\n",
    "joy_count=0\n",
    "sadness_count=0\n",
    "shame_count=0\n",
    "\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]=='sadness':\n",
    "        if y_pred[i]=='anger':\n",
    "            anger_count+=1\n",
    "        if y_pred[i]=='disgust':\n",
    "            disgust_count+=1\n",
    "        if y_pred[i]=='fear':\n",
    "            fear_count+=1\n",
    "        if y_pred[i]=='guilt':\n",
    "            guilt_count+=1\n",
    "        if y_pred[i]=='joy':\n",
    "            joy_count+=1\n",
    "        if y_pred[i]=='sadness':\n",
    "            sadness_count+=1\n",
    "        if y_pred[i]=='shame':\n",
    "            shame_count+=1\n",
    "\n",
    "print(anger_count)\n",
    "print(disgust_count)\n",
    "print(fear_count)\n",
    "print(guilt_count)\n",
    "print(joy_count)\n",
    "print(sadness_count)\n",
    "print(shame_count)\n",
    "#anger is mostly mistaken with shame:361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a8a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
