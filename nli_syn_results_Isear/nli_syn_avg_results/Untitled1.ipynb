{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b728dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9014457353075181, 0.9435913241106617, 0.9016841007596698, 0.7796272958359443, 0.830663724403736, 0.8517697268835277]\n"
     ]
    }
   ],
   "source": [
    "# Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]=='anger' and e[i]=='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]=='disgust' and e[i]=='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]=='fear' and e[i]=='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]=='guilt' and e[i]=='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]=='joy' and e[i]=='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]=='sadness' and e[i]=='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]=='shame' and e[i]=='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in guilt:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(guilt))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)\n",
    "\n",
    "#m=statistics.mean(anger)\n",
    "#print(m)\n",
    "#'anger': ['anger', 'annoyance', 'rage', 'outrage', 'fury', 'irritation']\n",
    "#anger [0.8915722581848453, 0.7823387655961138, 0.78387754666619, 0.8479829219646908, 0.7970985903397442, 0.9354425956684668]\n",
    "#'irritation'\n",
    "#'disgust': ['disgust', 'loathing', 'bitter', 'ugly', 'repugnance', 'revulsion']\n",
    "#disgust [0.9243350172016237, 0.8496597216531102, 0.7238734545718346, 0.8183288808512901, 0.9598341548017093, 0.9120812569345746]\n",
    "#'repugnance'\n",
    "#fear 'fear', 'horror', 'anxiety', 'terror', 'dread', 'scare'\n",
    "#fear [0.9606100347439448, 0.8260418523283054, 0.929620267127951, 0.8970007263918718, 0.9035965541154146, 0.967787853717804]\n",
    "#'scare'\n",
    "#'guilt': ['guilt', 'culpability', 'blameworthy', ' responsibility', 'misconduct', 'regret']\n",
    "#guilt [0.9014457353075181, 0.9435913241106617, 0.9016841007596698, 0.7796272958359443, 0.830663724403736, 0.8517697268835277]\n",
    "#'culpability'\n",
    "#'joy': ['joy', 'achievement', 'pleasure', 'awesome', 'happy', 'blessed']\n",
    "#joy [0.9036339007135756, 0.7720700915022654, 0.9228367147509338, 0.8015205601101345, 0.935461125405492, 0.7299588345778052]\n",
    "#'happiness'\n",
    "#'sadness': ['sadness', 'unhappy', 'grief', 'sorrow', 'loneliness', 'depression']\n",
    "#sadness [0.9504661499498808, 0.9388038222731598, 0.9007515149534016, 0.9303330078166064, 0.7487951127691385, 0.7432602845409843]\n",
    "#'sadness'\n",
    "#'shame': ['shame', 'humiliate', 'embarrassment', 'disgrace', 'dishonor', 'discredit']\n",
    "#shame [0.9345220033222342, 0.9548121391381421, 0.9505319093810247, 0.9215136187710289, 0.9284411342499218, 0.9099911152643759]\n",
    "# 'humiliate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8cc1e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7390925067063105, 0.6079888885927641, 0.6697451086530761, 0.5511395678877399, 0.8435531032847687, 0.7017663105587362]\n"
     ]
    }
   ],
   "source": [
    "# Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]=='anger' and e[i] !='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]=='disgust' and e[i] !='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]=='fear' and e[i] !='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]=='guilt' and e[i] !='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]=='joy' and e[i] !='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]=='sadness' and e[i]!='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]=='shame' and e[i]!='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in disgust:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(disgust))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)\n",
    "\n",
    "#m=statistics.mean(anger)\n",
    "#print(m)\n",
    "#'anger', 'annoyance', 'rage', 'outrage', 'fury', 'irritation'\n",
    "# anger [0.7944935133776878, 0.8505169725178502, 0.5955029603409874, 0.7519877179370944, 0.6339361201259723, 0.8961797884143324]\n",
    "#'irritation'\n",
    "#'disgust', 'loathing', 'bitter', 'ugly', 'repugnance', 'revulsion'\n",
    "# disgust [0.7390925067063105, 0.6079888885927641, 0.6697451086530761, 0.5511395678877399, 0.8435531032847687, 0.7017663105587362]\n",
    "#'repugnance'\n",
    "# fear [0.7600991166099632, 0.6288781821177101, 0.7620662660123724, 0.6192861656912608, 0.6821729623086956, 0.8139004784441936]\n",
    "#'scare'\n",
    "#guilt [0.7839212294642788, 0.8698427176925244, 0.7991742772062788, 0.6701088558697889, 0.7780364104001237, 0.7129228888982792]\n",
    "#'culpability'\n",
    "#joy [0.6055357484419658, 0.5492736650044172, 0.6451500193069242, 0.6113547904134589, 0.6888659085872616, 0.48492748767694854]\n",
    "#'happiness'\n",
    "#sadness [0.7466135875292821, 0.7910449285706272, 0.6193146888717699, 0.6967767968292659, 0.4456070933312488, 0.48851817310069845]\n",
    "#'unhappiness'\n",
    "#shame [0.6524708065986419, 0.6917790640871282, 0.7174428274332632, 0.5963307672724681, 0.692394197096894, 0.663599719538481]\n",
    "#'embarrassment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed59cb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7086140509571375, 0.6743446555034138, 0.6797089385439365, 0.6187811846959732, 0.6843077028739317, 0.6828667499289355]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]=='anger' and e[i] !='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]=='disgust' and e[i] !='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]=='fear' and e[i] !='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]!='guilt' and e[i] =='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]=='joy' and e[i] !='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]=='sadness' and e[i]!='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]=='shame' and e[i]!='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in guilt:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(guilt))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8cf9864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6732814383674031, 0.8454891713581693, 0.8132676862167953, 0.623696235074656, 0.7843823836725319, 0.6495507097649036]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_syn_probs_predicted_column.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]!='anger' and e[i]=='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]!='disgust' and e[i]=='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]!='fear' and e[i]=='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]!='guilt' and e[i]=='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]!='joy' and e[i]=='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]!='sadness' and e[i]=='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]!='shame' and e[i]=='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in guilt:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(guilt))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f3f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7691362409110148, 0.8005779924228884, 0.8138559584349984, 0.7308368393675777, 0.7900307920164004, 0.765515114782712]\n",
      "1079\n",
      "1066\n",
      "1076\n",
      "1049\n",
      "1092\n",
      "1082\n",
      "1071\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]=='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]=='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]=='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]=='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]=='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]=='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]=='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "#0:'anger', 1:'annoyance', 2:'rage', 3:'outrage', 4:'fury', 5:'irritation'\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in shame:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "         \n",
    "    \n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(shame))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)\n",
    "print(len(anger))\n",
    "print(len(disgust))\n",
    "print(len(fear))\n",
    "print(len(guilt))\n",
    "print(len(joy))\n",
    "print(len(sadness))\n",
    "print(len(shame))\n",
    "\n",
    "#anger [0.8351604203775351, 0.8219566856516548, 0.6744142791723049, 0.792200722775346, 0.702285922291519, 0.9126272294512822]\n",
    "#irritation\n",
    "#disgust [0.7877490760671808, 0.6714671561883522, 0.6839626854422435, 0.6213206257018056, 0.8740959685987869, 0.7570085103572678]\n",
    "#repugnance\n",
    "#fear [0.8998604443055823, 0.7663063909076232, 0.8788557649312236, 0.8128604412725416, 0.836510967750182, 0.9211639835140892]\n",
    "#scare\n",
    "#guilt [0.8517022838352605, 0.9123764706791527, 0.8582957674348789, 0.7332724937911654, 0.8083886744346189, 0.7930013798239944]\n",
    "#culpability\n",
    "#joy [0.8342960521082744, 0.7202474794780406, 0.8582465859571806, 0.7572878627631056, 0.878102897317735, 0.6729643637785218]\n",
    "#happiness\n",
    "#sadness [0.8939451067648718, 0.8978355523001841, 0.8227191232486978, 0.8655762025520942, 0.6647318911135314, 0.6726293848810159]\n",
    "#unhappiness\n",
    "#shame [0.7691362409110148, 0.8005779924228884, 0.8138559584349984, 0.7308368393675777, 0.7900307920164004, 0.765515114782712]\n",
    "#embarrassment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401ec13f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.827824680135536, 0.7071020030039722, 0.8528319878491494, 0.7390946600476817, 0.8659355252199418, 0.6760848666372589]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data1=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2.csv')\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data1['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if e[i]=='anger':\n",
    "        anger.append(d[i])\n",
    "    if e[i]=='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if e[i]=='fear':\n",
    "        fear.append(d[i])\n",
    "    if e[i]=='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if e[i]=='joy':\n",
    "        joy.append(d[i])\n",
    "    if e[i]=='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if e[i]=='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in joy:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        \n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if float_list[i]: \n",
    "            s+=float_list[i]\n",
    "    avg_syn_anger.append(s/len(joy))\n",
    "        \n",
    "        \n",
    "print(avg_syn_anger)\n",
    "#anger [0.829721364074839, 0.7620024765450107, 0.7819429217274393, 0.7621508874447857, 0.8149065492158788, 0.8098220097812381]\n",
    "#disgust [0.9050015989947222, 0.8833972318471902, 0.7310401270754571, 0.8436029181854859, 0.9044902261025379, 0.9008027591349034]\n",
    "#fear [0.8904026633143795, 0.7883778521917532, 0.8434584288895757, 0.8126582400591685, 0.8350283707536874, 0.8819118234397545]\n",
    "#guilt [0.8904026633143795, 0.7883778521917532, 0.8434584288895757, 0.8126582400591685, 0.8350283707536874, 0.8819118234397545]\n",
    "#[0.7581545388404339, 0.7677706728332291, 0.7352693511990736, 0.6472022713025573, 0.6974604895579544, 0.7339742928783858]\n",
    "\n",
    "#joy [0.8904026633143795, 0.7883778521917532, 0.8434584288895757, 0.8126582400591685, 0.8350283707536874, 0.8819118234397545]\n",
    "#[0.827824680135536, 0.7071020030039722, 0.8528319878491494, 0.7390946600476817, 0.8659355252199418, 0.6760848666372589\n",
    "#sadness [0.8904026633143795, 0.7883778521917532, 0.8434584288895757, 0.8126582400591685, 0.8350283707536874, 0.8819118234397545]\n",
    "#shame [0.8658759453574695, 0.8821501356367839, 0.8128518410935635, 0.7937069334998363, 0.8122277240773164, 0.8452417241654745] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d1cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548\n",
      "18\n",
      "258\n",
      "204\n",
      "4212\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv')\n",
    "\n",
    "d= data['probs_synonyms']\n",
    "e=data['emotion']\n",
    "d2=d.tolist()\n",
    "#print(d[0])\n",
    "\n",
    "label_list = data['labels'].tolist()\n",
    "anger=list()\n",
    "disgust=list()\n",
    "fear=list()\n",
    "guilt=list()\n",
    "joy=list()\n",
    "sadness=list()\n",
    "shame=list()\n",
    "\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i]=='anger':\n",
    "        anger.append(d[i])\n",
    "    if label_list[i]=='disgust':\n",
    "        disgust.append(d[i])\n",
    "    if label_list[i]=='fear':\n",
    "        fear.append(d[i])\n",
    "    if label_list[i]=='guilt':\n",
    "        guilt.append(d[i])\n",
    "    if label_list[i]=='joy':\n",
    "        joy.append(d[i])\n",
    "    if label_list[i]=='sadness':\n",
    "        sadness.append(d[i])\n",
    "    if label_list[i]=='shame':\n",
    "        shame.append(d[i])\n",
    "                    \n",
    "#m=np.sum(anger, axis=0)/len(anger)\n",
    "#m=np.average(anger, axis=0)\n",
    "#an=[sum(x)/len(x) for x in zip(*anger)]\n",
    "\n",
    "avg_syn_anger=list()\n",
    "#anger 6\n",
    "anger2=0\n",
    "annoyance2=0 \n",
    "rage2=0\n",
    "outrage2=0\n",
    "fury2=0\n",
    "irritation2=0\n",
    "\n",
    "#0:'anger', 1:'annoyance', 2:'rage', 3:'outrage', 4:'fury', 5:'irritation'\n",
    "#0:'disgust',1: 'loathing', 2:'bitterness', 3:'ugliness', 4:'repugnance', 5:'revulsion'\n",
    "disgust2=0 \n",
    "loathing2=0\n",
    "itterness2=0\n",
    "ugliness2=0\n",
    "repugnance2=0\n",
    "revulsion2=0\n",
    "\n",
    "for i in range(6):\n",
    "    s=0\n",
    "    for m in disgust:\n",
    "        m = m.strip(\"[]\")    \n",
    "        string_elements = m.split(\",\")\n",
    "        float_list = [float(element) for element in string_elements]\n",
    "        max_index=np.argmax(float_list)\n",
    "#        print(float_list)\n",
    "#        print(\"#\")\n",
    "        if max_index==0:\n",
    "            disgust2+=1\n",
    "        if max_index==1:\n",
    "            loathing2+=1\n",
    "        if max_index==2:\n",
    "            itterness2+=1\n",
    "        if max_index==3:\n",
    "            ugliness2+=1\n",
    "        if max_index==4:\n",
    "            repugnance2+=1\n",
    "        if max_index==5:\n",
    "            revulsion2+=1\n",
    "        \n",
    "        \n",
    "print(disgust2)\n",
    "print(loathing2)\n",
    "print(itterness2)\n",
    "print(ugliness2)\n",
    "print(repugnance2)\n",
    "print(revulsion2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07d5ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2.csv')\n",
    "data2=pd.read_csv('Isear_nli_syn_avg_two_syn_new.csv')\n",
    "#Isear_nli_syn_avg_expr_s.csv\n",
    "#Isear_nli_syn_avg_emo_s_prompt2.csv\n",
    "#Isear_nli_syn_avg_two_syn.csv\n",
    "prob_max=data['prob_max']\n",
    "emotion=data['emotion']\n",
    "prob_max2=data2['prob_max']\n",
    "expr_s= data2['emotion']\n",
    "predict_emotion=list()\n",
    "\n",
    "for i in range(len(prob_max)):\n",
    "    if prob_max[i]>=prob_max2[i]:\n",
    "        predict_emotion.append(emotion[i])\n",
    "    if prob_max[i]<prob_max2[i]:\n",
    "        predict_emotion.append(expr_s[i])\n",
    "\n",
    "dict2={'labels':data['labels'], 'text':data['text'], 'emotion':predict_emotion } \n",
    "df=pd.DataFrame(dict2)\n",
    "df.to_csv('Isear_nli_syn_avg_combined.csv', index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac74b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.46      0.58      0.52      1079\n",
      "     disgust       0.79      0.40      0.53      1066\n",
      "        fear       0.77      0.71      0.74      1076\n",
      "       guilt       0.42      0.70      0.52      1049\n",
      "         joy       0.92      0.87      0.90      1092\n",
      "     sadness       0.62      0.78      0.69      1082\n",
      "       shame       0.70      0.33      0.44      1071\n",
      "\n",
      "    accuracy                           0.62      7515\n",
      "   macro avg       0.67      0.62      0.62      7515\n",
      "weighted avg       0.67      0.62      0.62      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_combined.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['emotion']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c34a4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2.csv')\n",
    "data2=pd.read_csv('Isear_nli_syn_avg_two_syn_new.csv')\n",
    "#Isear_nli_syn_avg_emo_s_prompt2.csv\n",
    "#Isear_nli_syn_avg_expr_s.csv\n",
    "\n",
    "prob_emotion=data['prob_emotion']\n",
    "prob_expr_s=data2['prob_emotion']\n",
    "\n",
    "prob_emotion2=list()\n",
    "prob_expr_s2=list()\n",
    "\n",
    "for m in prob_emotion:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_emotion2.append(float_list)\n",
    "\n",
    "for m in prob_expr_s:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_expr_s2.append(float_list)\n",
    "\n",
    "\n",
    "predict=list()\n",
    "prob_emo=list()\n",
    "\n",
    "for i in range(len(prob_emotion2)):\n",
    "    combined_predict=list()\n",
    "    for j in range(len(prob_emotion2[0])):\n",
    "        a=(prob_emotion2[i][j]+prob_expr_s2[i][j])/2\n",
    "        combined_predict.append(a)\n",
    "    prob_emo.append(combined_predict)    \n",
    "\n",
    "dict_emo={0:'anger', 1:'disgust', 2:'fear', 3:'guilt', 4:'joy', 5:'sadness', 6:'shame'}\n",
    "\n",
    "for i in range(len(prob_emo)):\n",
    "    index=np.argmax(prob_emo[i])\n",
    "    predict.append(dict_emo[index])\n",
    "######\n",
    "\n",
    "dict2={'labels':data['labels'], 'text':data['text'], 'prob_emotion':prob_emo ,'emotion':predict} \n",
    "df=pd.DataFrame(dict2)\n",
    "df.to_csv('Isear_nli_syn_avg_combined_probs.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844b3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.53      0.51      0.52      1079\n",
      "     disgust       0.80      0.41      0.54      1066\n",
      "        fear       0.73      0.76      0.75      1076\n",
      "       guilt       0.41      0.71      0.52      1049\n",
      "         joy       0.92      0.90      0.91      1092\n",
      "     sadness       0.73      0.74      0.73      1082\n",
      "       shame       0.56      0.42      0.48      1071\n",
      "\n",
      "    accuracy                           0.64      7515\n",
      "   macro avg       0.67      0.64      0.64      7515\n",
      "weighted avg       0.67      0.64      0.64      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_combined_probs.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['emotion']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f302c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.46      0.58      0.52      1079\n",
      "     disgust       0.79      0.40      0.53      1066\n",
      "        fear       0.77      0.71      0.74      1076\n",
      "       guilt       0.42      0.70      0.52      1049\n",
      "         joy       0.92      0.87      0.90      1092\n",
      "     sadness       0.62      0.78      0.69      1082\n",
      "       shame       0.70      0.33      0.44      1071\n",
      "\n",
      "    accuracy                           0.62      7515\n",
      "   macro avg       0.67      0.62      0.62      7515\n",
      "weighted avg       0.67      0.62      0.62      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "#'Isear_nli_syn_avg_two_syn_new.csv'\n",
    "#'Isear_nli_syn_avg_emotion_prompt2.csv'\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_two_syn_new.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['emotion']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd26809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2.csv')\n",
    "data2=pd.read_csv('Isear_nli_syn_avg_two_syn_new.csv')\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_emo_s_prompt2.csv')\n",
    "#Isear_nli_syn_avg_emo_s_prompt2.csv\n",
    "#Isear_nli_syn_avg_expr_s.csv\n",
    "\n",
    "prob_emotion=data['prob_emotion']\n",
    "prob_expr_s=data2['prob_emotion']\n",
    "prob_expr_s3=data3['prob_emo_s']\n",
    "\n",
    "prob_emotion2=list()\n",
    "prob_expr_s2=list()\n",
    "prob_expr_s32=list()\n",
    "\n",
    "for m in prob_emotion:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_emotion2.append(float_list)\n",
    "\n",
    "for m in prob_expr_s:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_expr_s2.append(float_list)\n",
    "\n",
    "for m in prob_expr_s3:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_expr_s32.append(float_list)\n",
    "\n",
    "predict=list()\n",
    "prob_emo=list()\n",
    "\n",
    "for i in range(len(prob_emotion2)):\n",
    "    combined_predict=list()\n",
    "    for j in range(len(prob_emotion2[0])):\n",
    "        a=(prob_emotion2[i][j]+prob_expr_s2[i][j]+prob_expr_s32[i][j])/3\n",
    "        combined_predict.append(a)\n",
    "    prob_emo.append(combined_predict)    \n",
    "\n",
    "dict_emo={0:'anger', 1:'disgust', 2:'fear', 3:'guilt', 4:'joy', 5:'sadness', 6:'shame'}\n",
    "\n",
    "for i in range(len(prob_emo)):\n",
    "    index=np.argmax(prob_emo[i])\n",
    "    predict.append(dict_emo[index])\n",
    "######\n",
    "\n",
    "dict2={'labels':data['labels'], 'text':data['text'], 'prob_emotion':prob_emo ,'emotion':predict} \n",
    "df=pd.DataFrame(dict2)\n",
    "df.to_csv('Isear_nli_syn_avg_combined_probs2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdd8202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.53      0.46      0.49      1079\n",
      "     disgust       0.80      0.38      0.51      1066\n",
      "        fear       0.74      0.73      0.74      1076\n",
      "       guilt       0.36      0.79      0.50      1049\n",
      "         joy       0.92      0.90      0.91      1092\n",
      "     sadness       0.71      0.75      0.73      1082\n",
      "       shame       0.66      0.31      0.42      1071\n",
      "\n",
      "    accuracy                           0.62      7515\n",
      "   macro avg       0.67      0.62      0.61      7515\n",
      "weighted avg       0.68      0.62      0.62      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_combined_probs2.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['emotion']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918555ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isear_nli_syn_remove_syn4_new.csv\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#Isear_nli_syn_avg_emotion_prompt2_syn_probs.csv\n",
    "data=pd.read_csv('Isear_nli_syn_avg_emotion_prompt2.csv')\n",
    "data2=pd.read_csv('Isear_nli_syn_emotion_prompt_max_new2.csv')\n",
    "#Isear_nli_syn_emotion_prompt_max_new2.csv\n",
    "#Isear_nli_syn_avg_emo_s_prompt2.csv\n",
    "#Isear_nli_syn_avg_expr_s.csv\n",
    "\n",
    "prob_emotion=data['prob_emotion']\n",
    "prob_expr_s=data2['prob_emotion']\n",
    "\n",
    "prob_emotion2=list()\n",
    "prob_expr_s2=list()\n",
    "\n",
    "for m in prob_emotion:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_emotion2.append(float_list)\n",
    "\n",
    "for m in prob_expr_s:\n",
    "    m = m.strip(\"[]\")    \n",
    "    string_elements = m.split(\",\")\n",
    "    float_list = [float(element) for element in string_elements]\n",
    "    prob_expr_s2.append(float_list)\n",
    "\n",
    "\n",
    "predict=list()\n",
    "prob_emo=list()\n",
    "\n",
    "for i in range(len(prob_emotion2)):\n",
    "    combined_predict=list()\n",
    "    for j in range(len(prob_emotion2[0])):\n",
    "        a=(prob_emotion2[i][j]+prob_expr_s2[i][j])/2\n",
    "        combined_predict.append(a)\n",
    "    prob_emo.append(combined_predict)    \n",
    "\n",
    "dict_emo={0:'anger', 1:'disgust', 2:'fear', 3:'guilt', 4:'joy', 5:'sadness', 6:'shame'}\n",
    "\n",
    "for i in range(len(prob_emo)):\n",
    "    index=np.argmax(prob_emo[i])\n",
    "    predict.append(dict_emo[index])\n",
    "######\n",
    "\n",
    "dict2={'labels':data['labels'], 'text':data['text'], 'prob_emotion':prob_emo ,'emotion':predict} \n",
    "df=pd.DataFrame(dict2)\n",
    "df.to_csv('Isear_nli_syn_avg_combined_probs2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0841f67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.46      0.50      1079\n",
      "     disgust       0.78      0.44      0.56      1066\n",
      "        fear       0.64      0.83      0.72      1076\n",
      "       guilt       0.53      0.64      0.58      1049\n",
      "         joy       0.86      0.93      0.89      1092\n",
      "     sadness       0.69      0.76      0.72      1082\n",
      "       shame       0.54      0.50      0.52      1071\n",
      "\n",
      "    accuracy                           0.65      7515\n",
      "   macro avg       0.66      0.65      0.64      7515\n",
      "weighted avg       0.66      0.65      0.64      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_combined_probs2.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['emotion']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2649c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.53      0.52      0.52      1079\n",
      "     disgust       0.76      0.33      0.46      1066\n",
      "        fear       0.59      0.84      0.69      1076\n",
      "       guilt       0.48      0.66      0.56      1049\n",
      "         joy       0.90      0.92      0.91      1092\n",
      "     sadness       0.70      0.73      0.72      1082\n",
      "       shame       0.54      0.38      0.45      1071\n",
      "\n",
      "    accuracy                           0.63      7515\n",
      "   macro avg       0.64      0.63      0.62      7515\n",
      "weighted avg       0.64      0.63      0.62      7515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Isear_nli_syn_avg_expr_s.csv\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "data3=pd.read_csv('Isear_nli_syn_avg_expr_s.csv')\n",
    "\n",
    "label=data3['labels']\n",
    "emotion=data3['expr_s']\n",
    "print(classification_report(label, emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a741f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
